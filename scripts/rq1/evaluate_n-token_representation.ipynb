{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e38be53",
   "metadata": {},
   "source": [
    "# N-token representaion Precision, Recall, F1\n",
    "\n",
    "This notebook computes TP, FP, Precision, Recall, and F1 for N-token representation on:\n",
    "\n",
    "1. **Developer-Informed Oracle**  \n",
    "2. **Defects4J**\n",
    "\n",
    "The JSON files referenced here are generated by the replication scripts included in the package.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21f72599",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "import json\n",
    "from typing import List, Dict, Tuple, Set\n",
    "\n",
    "# ---------- Data structure ----------\n",
    "@dataclass(frozen=True)\n",
    "class BugFixInducingPair:\n",
    "    repo_name: str\n",
    "    fix_commit_hash: str\n",
    "    inducing_commit_hash: str\n",
    "\n",
    "# ---------- TP / FP counting ----------\n",
    "def get_tp_fp(file_json: List[Dict]) -> Tuple[Set[BugFixInducingPair],\n",
    "                                              Set[BugFixInducingPair]]:\n",
    "    \"\"\"\n",
    "    Return unique TP and FP pairs for a parsed JSON list.\n",
    "    Duplicate inducing hashes for the same fix commit are ignored.\n",
    "    \"\"\"\n",
    "    tp: Set[BugFixInducingPair] = set()\n",
    "    fp: Set[BugFixInducingPair] = set()\n",
    "\n",
    "    for obj in file_json:\n",
    "        repo = obj[\"repo_name\"]\n",
    "        fix  = obj[\"fix_commit_hash\"]\n",
    "        oracle = set(obj[\"bug_commit_hash\"])\n",
    "        preds  = obj.get(\"inducing_commit_hash\", [])\n",
    "\n",
    "        pred_hashes = {p[\"commit_hash\"] for p in preds}   # de-duplicate\n",
    "\n",
    "        for h in pred_hashes:\n",
    "            pair = BugFixInducingPair(repo, fix, h)\n",
    "            (tp if h in oracle else fp).add(pair)\n",
    "\n",
    "    return tp, fp\n",
    "\n",
    "# ---------- Metric helpers ----------\n",
    "def get_scores(tp: int, fp: int, fn: int) -> Tuple[float, float, float]:\n",
    "    precision = tp / (tp + fp) if (tp + fp) else 0.0\n",
    "    recall    = tp / (tp + fn) if (tp + fn) else 0.0\n",
    "    f1        = (2 * precision * recall) / (precision + recall) if (precision + recall) else 0.0\n",
    "    return precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bb4cf9",
   "metadata": {},
   "source": [
    "## 1. Developer-Informed Oracle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "704adfe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== B-SZZ ===\n",
      "TP:    51  FP:   133\n",
      "Precision: 0.277  Recall: 0.671  F1: 0.392\n",
      "\n",
      "=== 1-token ===\n",
      "TP:    43  FP:   131\n",
      "Precision: 0.247  Recall: 0.566  F1: 0.344\n",
      "\n",
      "=== 2-token ===\n",
      "TP:    52  FP:   157\n",
      "Precision: 0.249  Recall: 0.684  F1: 0.365\n",
      "\n",
      "=== 3-token ===\n",
      "TP:    53  FP:   164\n",
      "Precision: 0.244  Recall: 0.697  F1: 0.362\n",
      "\n",
      "=== 4-token ===\n",
      "TP:    55  FP:   193\n",
      "Precision: 0.222  Recall: 0.724  F1: 0.340\n",
      "\n",
      "=== 5-token ===\n",
      "TP:    56  FP:   197\n",
      "Precision: 0.221  Recall: 0.737  F1: 0.340\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BASE_DIR = Path().resolve().parent.parent\n",
    "\n",
    "EVAL_FILES_DIO = {\n",
    "    \"B-SZZ\":  BASE_DIR / \"dataset/pyszz_v2/json-output-raw/rq1/developer-informed-oracle/dio_bic_conf_original.json\",\n",
    "    \"1-token\": BASE_DIR / \"dataset/pyszz_v2/json-output-raw/rq1/developer-informed-oracle/dio_bic_conf_1token.json\",\n",
    "    \"2-token\": BASE_DIR / \"dataset/pyszz_v2/json-output-raw/rq1/developer-informed-oracle/dio_bic_conf_2token.json\",\n",
    "    \"3-token\": BASE_DIR / \"dataset/pyszz_v2/json-output-raw/rq1/developer-informed-oracle/dio_bic_conf_3token.json\",\n",
    "    \"4-token\": BASE_DIR / \"dataset/pyszz_v2/json-output-raw/rq1/developer-informed-oracle/dio_bic_conf_4token.json\",\n",
    "    \"5-token\": BASE_DIR / \"dataset/pyszz_v2/json-output-raw/rq1/developer-informed-oracle/dio_bic_conf_5token.json\",\n",
    "}\n",
    "\n",
    "for label, path in EVAL_FILES_DIO.items():\n",
    "    if not path.is_file():\n",
    "        print(f\"[WARN] missing → {label}: {path}\")\n",
    "        continue\n",
    "\n",
    "    with path.open(encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    tp_set, fp_set = get_tp_fp(data)\n",
    "    tp, fp = len(tp_set), len(fp_set)\n",
    "    fn = sum(len(obj[\"bug_commit_hash\"]) for obj in data) - tp\n",
    "\n",
    "    precision, recall, f1 = get_scores(tp, fp, fn)\n",
    "\n",
    "    print(f\"=== {label} ===\")\n",
    "    print(f\"TP: {tp:5d}  FP: {fp:5d}\")\n",
    "    print(f\"Precision: {precision:.3f}  Recall: {recall:.3f}  F1: {f1:.3f}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbe29bd",
   "metadata": {},
   "source": [
    "## 2. Defects4J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d593f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== B-SZZ ===\n",
      "TP:    80  FP:   146\n",
      "Precision: 0.354  Recall: 0.615  F1: 0.449\n",
      "\n",
      "=== 1-token ===\n",
      "TP:    66  FP:    95\n",
      "Precision: 0.410  Recall: 0.508  F1: 0.454\n",
      "\n",
      "=== 2-token ===\n",
      "TP:    83  FP:   125\n",
      "Precision: 0.399  Recall: 0.638  F1: 0.491\n",
      "\n",
      "=== 3-token ===\n",
      "TP:    91  FP:   151\n",
      "Precision: 0.376  Recall: 0.700  F1: 0.489\n",
      "\n",
      "=== 4-token ===\n",
      "TP:    95  FP:   173\n",
      "Precision: 0.354  Recall: 0.731  F1: 0.477\n",
      "\n",
      "=== 5-token ===\n",
      "TP:    98  FP:   211\n",
      "Precision: 0.317  Recall: 0.754  F1: 0.446\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EVAL_FILES_D4J = {\n",
    "    \"B-SZZ\":  BASE_DIR / \"dataset/pyszz_v2/json-output-raw/rq1/defects4j/d4j_bic_conf_original.json\",\n",
    "    \"1-token\": BASE_DIR / \"dataset/pyszz_v2/json-output-raw/rq1/defects4j/d4j_bic_conf_1token.json\",\n",
    "    \"2-token\": BASE_DIR / \"dataset/pyszz_v2/json-output-raw/rq1/defects4j/d4j_bic_conf_2token.json\",\n",
    "    \"3-token\": BASE_DIR / \"dataset/pyszz_v2/json-output-raw/rq1/defects4j/d4j_bic_conf_3token.json\",\n",
    "    \"4-token\": BASE_DIR / \"dataset/pyszz_v2/json-output-raw/rq1/defects4j/d4j_bic_conf_4token.json\",\n",
    "    \"5-token\": BASE_DIR / \"dataset/pyszz_v2/json-output-raw/rq1/defects4j/d4j_bic_conf_5token.json\",\n",
    "}\n",
    "\n",
    "for label, path in EVAL_FILES_D4J.items():\n",
    "    if not path.is_file():\n",
    "        print(f\"[WARN] missing → {label}: {path}\")\n",
    "        continue\n",
    "\n",
    "    with path.open(encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    tp_set, fp_set = get_tp_fp(data)\n",
    "    tp, fp = len(tp_set), len(fp_set)\n",
    "    fn = sum(len(obj[\"bug_commit_hash\"]) for obj in data) - tp\n",
    "\n",
    "    precision, recall, f1 = get_scores(tp, fp, fn)\n",
    "\n",
    "    print(f\"=== {label} ===\")\n",
    "    print(f\"TP: {tp:5d}  FP: {fp:5d}\")\n",
    "    print(f\"Precision: {precision:.3f}  Recall: {recall:.3f}  F1: {f1:.3f}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
