{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f981e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Wrote 130 records to /local2/i-kondo/szz/majority-voting-szz-replication-package/dataset/pyszz_v2/json-input-raw/defects4j/d4j_bugfix_commits_original.json\n"
     ]
    }
   ],
   "source": [
    "import subprocess, csv, json, sys\n",
    "from pathlib import Path\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 0. Paths / constants\n",
    "# ---------------------------------------------------------------------------\n",
    "BASE_DIR = Path().resolve().parents[3]\n",
    "INPUT_CSV   = BASE_DIR / \"dataset\" / \"preparation\" / \"d4j_bug_commit_hash.csv\"\n",
    "OUTPUT_JSON = (\n",
    "    BASE_DIR\n",
    "    / \"dataset\" / \"pyszz_v2\" / \"json-input-raw\" / \"defects4j\"\n",
    "    / \"d4j_bugfix_commits_original.json\"\n",
    ")\n",
    "GITHUB_ROOT = BASE_DIR / \"dataset\" / \"repositories\" / \"defects4j\" / \"github.com\"\n",
    "\n",
    "# Primary mapping: Defects4J project ID → official GitHub org/repo\n",
    "PRIMARY_MAP: dict[str, str] = {\n",
    "    \"Cli\":          \"apache/commons-cli\",\n",
    "    \"Closure\":      \"google/closure-compiler\",\n",
    "    \"Codec\":        \"apache/commons-codec\",\n",
    "    \"Compress\":     \"apache/commons-compress\",\n",
    "    \"Gson\":         \"google/gson\",\n",
    "    \"JacksonCore\":  \"FasterXML/jackson-core\",\n",
    "    \"Jsoup\":        \"jhy/jsoup\",\n",
    "    \"Lang\":         \"apache/commons-lang\",\n",
    "    \"Math\":         \"apache/commons-math\",\n",
    "    \"Mockito\":      \"mockito/mockito\",\n",
    "    \"Time\":         \"JodaOrg/joda-time\",\n",
    "}\n",
    "\n",
    "# Fallback mapping: same repository name but under the Defects4J organisation\n",
    "FALLBACK_ORG = \"Defects4J\"\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 1. Helper utilities\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def repo_path(org_repo: str) -> Path:\n",
    "    \"\"\"Return the absolute path to the local clone of *org_repo*.\"\"\"\n",
    "    return GITHUB_ROOT / Path(org_repo)\n",
    "\n",
    "\n",
    "def ensure_full_history(repo: Path) -> None:\n",
    "    \"\"\"Convert a shallow clone into a full clone if required (best‑effort).\"\"\"\n",
    "    shallow_file = repo / \".git\" / \"shallow\"\n",
    "    if shallow_file.exists():\n",
    "        subprocess.call(\n",
    "            [\"git\", \"-C\", str(repo), \"fetch\", \"--unshallow\"],\n",
    "            stdout=subprocess.DEVNULL,\n",
    "            stderr=subprocess.DEVNULL,\n",
    "        )\n",
    "\n",
    "\n",
    "def rev_parse(repo: Path, short: str):\n",
    "    \"\"\"Run `git rev-parse` inside *repo* and return the full SHA or *None*.\"\"\"\n",
    "    try:\n",
    "        return subprocess.check_output(\n",
    "            [\"git\", \"-C\", str(repo), \"rev-parse\", short],\n",
    "            text=True,\n",
    "            stderr=subprocess.DEVNULL,\n",
    "        ).strip()\n",
    "    except subprocess.CalledProcessError:\n",
    "        return None\n",
    "\n",
    "\n",
    "def resolve_short_sha(org_repo: str, short: str):\n",
    "    \"\"\"Resolve *short* in the primary repo, then in the Defects4J mirror.\n",
    "    Returns a tuple *(full_sha_or_None, path_tried)*.\"\"\"\n",
    "    # 1) primary repository\n",
    "    repo_dir = repo_path(org_repo)\n",
    "    if repo_dir.exists():\n",
    "        ensure_full_history(repo_dir)\n",
    "        sha = rev_parse(repo_dir, short)\n",
    "        if sha:\n",
    "            return sha, str(repo_dir)\n",
    "    # 2) fallback mirror\n",
    "    org, repo = org_repo.split(\"/\", 1)\n",
    "    mirror = f\"{FALLBACK_ORG}/{repo}\"\n",
    "    mirror_dir = repo_path(mirror)\n",
    "    if mirror_dir.exists():\n",
    "        ensure_full_history(mirror_dir)\n",
    "        sha = rev_parse(mirror_dir, short)\n",
    "        if sha:\n",
    "            return sha, str(mirror_dir)\n",
    "    return None, str(repo_dir)\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 2. Load CSV → in‑memory records\n",
    "# ---------------------------------------------------------------------------\n",
    "records: list[dict] = []\n",
    "with open(INPUT_CSV, newline=\"\", encoding=\"utf-8\") as f:\n",
    "    for idx, row in enumerate(csv.DictReader(f)):\n",
    "        records.append(\n",
    "            {\n",
    "                \"id\": idx + 10000,\n",
    "                \"pid\": row[\"pid\"].strip(),       # original project ID (e.g. \"Closure\")\n",
    "                \"bug_id\": row[\"vid\"].strip(),    # bug.id as a string\n",
    "                \"bug_commit_hash\": [row[\"commit\"].strip()],\n",
    "            }\n",
    "        )\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 3. Build a lookup table from active‑bugs.csv (keyed by *pid*)\n",
    "# ---------------------------------------------------------------------------\n",
    "active_bugs: dict[str, dict[str, str]] = {}\n",
    "for pid in {r[\"pid\"] for r in records}:\n",
    "    csv_path = (\n",
    "        BASE_DIR / \"dataset\" / \"defects4j\" / \"framework\" / \"projects\" / pid / \"active-bugs.csv\"\n",
    "    )\n",
    "    table: dict[str, str] = {}\n",
    "    if csv_path.exists():\n",
    "        with open(csv_path, newline=\"\", encoding=\"utf-8\") as f:\n",
    "            for row in csv.DictReader(f):\n",
    "                table[row[\"bug.id\"].strip()] = row[\"revision.id.fixed\"].strip()\n",
    "    else:\n",
    "        print(f\"[warn] {csv_path} does not exist.\", file=sys.stderr)\n",
    "    active_bugs[pid] = table\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 4. Enrich each record and resolve its short SHA\n",
    "# ---------------------------------------------------------------------------\n",
    "for rec in records:\n",
    "    pid = rec.pop(\"pid\")                    # e.g. \"Closure\"\n",
    "    org_repo = PRIMARY_MAP.get(pid, pid)    # mapped <org>/<repo>\n",
    "\n",
    "    # a) add the corresponding fix commit\n",
    "    rec[\"fix_commit_hash\"] = active_bugs.get(pid, {}).get(rec[\"bug_id\"], None)\n",
    "\n",
    "    # b) resolve the 7‑char SHA to a 40‑char SHA‑1\n",
    "    short = rec[\"bug_commit_hash\"][0]\n",
    "    full_sha, path_seen = resolve_short_sha(org_repo, short)\n",
    "    if full_sha:\n",
    "        rec[\"bug_commit_hash\"][0] = full_sha\n",
    "    else:\n",
    "        print(\n",
    "            f\"[warn] {org_repo}: failed to resolve '{rec['bug_commit_hash']}'.\",\n",
    "            file=sys.stderr,\n",
    "        )\n",
    "\n",
    "    # c) finalise record\n",
    "    rec[\"repo_name\"] = org_repo\n",
    "    rec.pop(\"bug_id\", None)\n",
    "    rec[\"language\"] = [\"java\"]\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# 5. Write the resulting JSON\n",
    "# ---------------------------------------------------------------------------\n",
    "with open(OUTPUT_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(records, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(f\"✅ Wrote {len(records)} records to {OUTPUT_JSON}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
